image_transformations:
  image_size: 256
data_loader:
  batch_size: 16
  workers: 4
  split_ratio: 0.8
training:
  model: "unet"               # options: "unet" or "transformer"
  transformer_model: "nvidia/mit-b0" # options: "nvidia/mit-b0" or "nvidia/segformer-b0-finetuned-ade-512-512"
  optimizer:
    lr: 1e-3
  max_epochs: 200
  limits_batches:
    train: 1.0
    val: 1.0
checkpoints:
  dirpath: "models/"
