image_transformations:
  image_size: 256
data_loader:
  batch_size: 16
  workers: 4
  split_ratio: 0.8
training:
  model: "transformer"               # options: "unet" or "transformer"
  transformer_model: "nvidia/mit-b0" # options: "nvidia/mit-b0" or "nvidia/segformer-b0-finetuned-ade-512-512"
  optimizer:
    lr: 1e-3
  max_epochs: 200
  limits_batches:
    train: 1.0
    val: 1.0
checkpoints:
  dirpath: "models/"
  filename: "transformer_mit-b0_bs=32_img_size=256_epoch=98-val_loss=1.17696-val_mean_iou=0.65841.ckpt"
